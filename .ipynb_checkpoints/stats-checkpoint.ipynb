{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anton/optimization-methods\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anton/optimization-methods/embeddings-for-trees\n"
     ]
    }
   ],
   "source": [
    "%cd embeddings-for-trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "# from dataset import PathContextDataModule\n",
    "from data_module.jsonl_data_module import JsonlDataModule\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from nltk.translate.meteor_score import single_meteor_score\n",
    "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu\n",
    "from rouge import Rouge\n",
    "from bert_score import score as bert_score\n",
    "\n",
    "from scipy.stats import wilcoxon, mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "lemma_function = WordNetLemmatizer()\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.load(\"config/tree_lstm_med_10per1.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is already downloaded\n"
     ]
    }
   ],
   "source": [
    "data_module = JsonlDataModule(config)\n",
    "data_module.prepare_data()\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_label = data_module._vocabulary.id_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tokens, stem=True, lemmatize=False):\n",
    "    result = []\n",
    "    for token, tag in pos_tag(tokens):\n",
    "        if lemmatize:\n",
    "            result.append(lemma_function.lemmatize(token, tag_map[tag[0]]))\n",
    "        elif stem:\n",
    "            result.append(porter.stem(token))\n",
    "        else:\n",
    "            result.append(token)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyps_refs(predict_file = \"/home/anton/data/outputs/Lookahead_RAdam_standart_lr/tensor/Lookahead_RAdam_test_outputs.pkl\",\n",
    "                  use_first=10):\n",
    "    test_dataloader = data_module.test_dataloader()\n",
    "    predictions = torch.load(f\"{predict_file}\", map_location=torch.device('cpu'))\n",
    "\n",
    "    hyps = []; refs = []\n",
    "    \n",
    "    if use_first is None:\n",
    "        x = zip(predictions, test_dataloader)\n",
    "    else:\n",
    "        x = itertools.islice(zip(predictions, test_dataloader), use_first)\n",
    "    \n",
    "    for batch_our, batch_ref in x:\n",
    "        batch_ref = batch_ref[0]\n",
    "        for batch_idx in range(batch_our.size(1)):\n",
    "            res_our = []\n",
    "            res_ref = []\n",
    "            for idx in batch_our[:, batch_idx]:\n",
    "                if idx in [1, 3]:\n",
    "                    break\n",
    "                res_our.append(id_to_label[idx.item()])\n",
    "            for idx in batch_ref[:, batch_idx]:\n",
    "                if idx in [1, 3]:\n",
    "                    break\n",
    "                res_ref.append(id_to_label[idx.item()])\n",
    "\n",
    "            res_our = preprocess(res_our[1:], stem=False, lemmatize=True)\n",
    "            res_ref = preprocess(res_ref[1:], stem=False, lemmatize=True)\n",
    "            \n",
    "            if len(res_ref) > 0:\n",
    "                if len(res_our) == 0:\n",
    "                    res_our = ['xxx']\n",
    "                hyps.append(' '.join(res_our)); refs.append(' '.join(res_ref))\n",
    "\n",
    "    return hyps, refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    def __init__(self, hyps, refs):\n",
    "        self.hyps = hyps\n",
    "        self.refs = refs\n",
    "    \n",
    "    def get_statistics(self, with_symbolic=False):\n",
    "        result = {\n",
    "            'scores': {},\n",
    "            'score': {}\n",
    "        }\n",
    "        for func in dir(Metrics):\n",
    "            if callable(getattr(Metrics, func)) and func[0] != '_' and func != 'get_statistics':\n",
    "                if not with_symbolic and 'symb' in func:\n",
    "                    continue\n",
    "                metric_result = getattr(Metrics, func)(self)\n",
    "                result['scores'].update(metric_result['scores'])\n",
    "                result['score'].update(metric_result['score'])\n",
    "    \n",
    "        return result\n",
    "    \n",
    "    def bert(self):\n",
    "        (P, R, F), hashname = bert_score(self.hyps, self.refs, lang=\"en\", return_hash=True)\n",
    "        return {\n",
    "            'scores': {\n",
    "                'bert-P': P.cpu().detach().numpy(),\n",
    "                'bert-R': R.cpu().detach().numpy(),\n",
    "                'bert-F': F.cpu().detach().numpy()\n",
    "            },\n",
    "            'score': {\n",
    "                'bert-P': P.mean().item(),\n",
    "                'bert-R': R.mean().item(),\n",
    "                'bert-F': F.mean().item()\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def meteor(self):\n",
    "        scores = []\n",
    "        for hyp, ref in zip(self.hyps, self.refs):\n",
    "            scores.append(single_meteor_score(ref, hyp))\n",
    "        \n",
    "        return {\n",
    "            'scores': {\n",
    "                'meteor': np.array(scores)\n",
    "            },\n",
    "            'score': {\n",
    "                'meteor': np.mean(scores)\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def bleu(self):\n",
    "        scores = []\n",
    "        for hyp, ref in zip(self.hyps, self.refs):\n",
    "            scores.append(sentence_bleu([ref], hyp))\n",
    "        \n",
    "        return {\n",
    "            'scores': {\n",
    "                'bleu': np.array(scores)\n",
    "            },\n",
    "            'score': {\n",
    "                'bleu': corpus_bleu([[ref] for ref in self.refs], self.hyps)\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def symb_rouge_l(self):\n",
    "        rouge = Rouge(metrics=['rouge-l'])\n",
    "        scores_dict = defaultdict(list)\n",
    "        \n",
    "        hyps_symb = [' '.join(h.replace(' ', '')) for h in hyps]\n",
    "        refs_symb = [' '.join(r.replace(' ', '')) for r in refs]\n",
    "\n",
    "        scores = rouge.get_scores(hyps_symb, refs_symb)\n",
    "        for score in scores:\n",
    "            batch = {}\n",
    "            for sub in score:\n",
    "                batch.update({sub + k.upper(): v for k, v in score[sub].items()})\n",
    "\n",
    "            for title in batch:\n",
    "                scores_dict['symb-' + title].append(batch[title])\n",
    "\n",
    "        scores_dict = dict(scores_dict)\n",
    "        score_dict = {}\n",
    "        for title in scores_dict:\n",
    "            scores_dict[title] = np.array(scores_dict[title])\n",
    "            score_dict[title] = scores_dict[title].mean()\n",
    "        \n",
    "        return {\n",
    "            'scores': scores_dict,\n",
    "            'score': score_dict\n",
    "        }\n",
    "    \n",
    "    def rouge(self):\n",
    "        rouge = Rouge()\n",
    "        scores_dict = defaultdict(list)\n",
    "\n",
    "        scores = rouge.get_scores(hyps, refs)\n",
    "        for score in scores:\n",
    "            batch = {}\n",
    "            for sub in score:\n",
    "                batch.update({sub + k.upper(): v for k, v in score[sub].items()})\n",
    "\n",
    "            for title in batch:\n",
    "                scores_dict[title].append(batch[title])\n",
    "\n",
    "        scores_dict = dict(scores_dict)\n",
    "        score_dict = {}\n",
    "        for title in scores_dict:\n",
    "            scores_dict[title] = np.array(scores_dict[title])\n",
    "            score_dict[title] = scores_dict[title].mean()\n",
    "        \n",
    "        return {\n",
    "            'scores': scores_dict,\n",
    "            'score': score_dict\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symbolic scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/home/anton/data/outputs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps, refs = get_hyps_refs(predict_file=DATA_DIR + \"SGD_global/tensor/sgd_global_predictions.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2078aee258d54c9481d48ce60975f5b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6342f297a85e40a2814cef348045e43a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b522571561342daa47a8c94312a0f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3955a6a306b64fd68ec6a3847cc91dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anton/opt-met-exps/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/anton/opt-met-exps/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/anton/opt-met-exps/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "metrics = Metrics(hyps, refs)\n",
    "symb_metrics = metrics.get_statistics(with_symbolic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([182., 189., 438., 463., 285., 192.,  56.,  47.,  28.,   2.]),\n",
       " array([0.        , 0.08333333, 0.16666667, 0.25      , 0.33333333,\n",
       "        0.41666666, 0.5       , 0.58333333, 0.66666666, 0.75      ,\n",
       "        0.83333333]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(symb_metrics['scores']['symb-rouge-lF'][symb_metrics['scores']['meteor'] < 1e-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific = ((symb_metrics['scores']['meteor'] < 1e-1) * (symb_metrics['scores']['symb-rouge-lF'] > 0.6)).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 0.6\n",
      "count: 54\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.7142857093877552\n",
      "hyp: set on listener listener listener listener listener , ref: register\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.6666666618055556\n",
      "hyp: on intent intent , ref: open file\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.7142857093877552\n",
      "hyp: set on listener listener listener listener listener , ref: register\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.6249999953125001\n",
      "hyp: add on listener listener , ref: register\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.6666666618055556\n",
      "hyp: on intent intent , ref: open file\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.6249999953125001\n",
      "hyp: add on listener listener , ref: register\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.6153846106508877\n",
      "hyp: on listener listener listener listener listener listener , ref: init event\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.6153846106508877\n",
      "hyp: on listener listener listener listener listener listener , ref: init event\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.6666666617283951\n",
      "hyp: reset , ref: set go\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.6153846106508877\n",
      "hyp: on listener listener listener listener listener listener , ref: init event\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.6153846106508877\n",
      "hyp: on listener listener listener listener listener listener , ref: init event\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.6153846106508877\n",
      "hyp: on listener listener listener listener listener listener , ref: init event\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.7499999953125\n",
      "hyp: set , ref: select\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.6666666617283951\n",
      "hyp: reset , ref: set go\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.7499999953125\n",
      "hyp: set , ref: select\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.6153846106508877\n",
      "hyp: on listener listener listener listener listener listener , ref: init event\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.6153846106508877\n",
      "hyp: on listener listener , ref: init event\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.6153846106508877\n",
      "hyp: on listener listener , ref: init event\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.6666666622222223\n",
      "hyp: stop stop , ref: on swipe top\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.6666666622222223\n",
      "hyp: set , ref: reset offset\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.7499999953125\n",
      "hyp: set , ref: setup\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.7499999953125\n",
      "hyp: set , ref: setup\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.7499999953125\n",
      "hyp: set , ref: setup\n",
      "\n",
      "meteor: 0.08928571428571427\n",
      "symb. rouge-lF: 0.6666666622222223\n",
      "hyp: init parent , ref: build parent layer list if need\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.6666666618666668\n",
      "hyp: create test , ref: agent certificate\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.7499999953125\n",
      "hyp: set , ref: setup\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.8333333283333335\n",
      "hyp: get status , ref: agent state\n",
      "\n",
      "meteor: 0.07575757575757576\n",
      "symb. rouge-lF: 0.6086956472589792\n",
      "hyp: test throw locale , ref: should return locale for the current thread\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.7499999953125\n",
      "hyp: set , ref: setup\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.7499999953125\n",
      "hyp: set , ref: setup\n",
      "\n",
      "meteor: 0.08620689655172413\n",
      "symb. rouge-lF: 0.7999999952000001\n",
      "hyp: test return configuration configuration , ref: should check for equality for configuration\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.7499999953125\n",
      "hyp: set , ref: setup\n",
      "\n",
      "meteor: 0.09803921568627452\n",
      "symb. rouge-lF: 0.6923076873076923\n",
      "hyp: should not not not same with , ref: should include when the text\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.7499999953125\n",
      "hyp: set , ref: setup\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.7499999953125\n",
      "hyp: set , ref: setup\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.7499999953125\n",
      "hyp: set , ref: setup\n",
      "\n",
      "meteor: 0.07142857142857142\n",
      "symb. rouge-lF: 0.6896551677051131\n",
      "hyp: test not valid valid not be not , ref: should be invalid if message be empty\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.7499999953125\n",
      "hyp: set , ref: setup\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.7499999953125\n",
      "hyp: set , ref: setup\n",
      "\n",
      "meteor: 0.07692307692307691\n",
      "symb. rouge-lF: 0.6666666622222223\n",
      "hyp: test should , ref: agent with no ip address should be\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.639999995392\n",
      "hyp: test not identifier , ref: should contain counter if stage have rerun\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.7499999953125\n",
      "hyp: set , ref: setup\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.7499999953125\n",
      "hyp: set , ref: setup\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.7499999953125\n",
      "hyp: set , ref: setup\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.6206896503210465\n",
      "hyp: test return service config config config config , ref: should provide set of schedulable material\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.7499999953125\n",
      "hyp: set , ref: setup\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.6666666617283951\n",
      "hyp: send , ref: append\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.7499999953125\n",
      "hyp: set , ref: setup\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.7499999953125\n",
      "hyp: set , ref: setup\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.6666666622222223\n",
      "hyp: tear , ref: teardown\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.7499999953125\n",
      "hyp: set , ref: setup\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.7499999953125\n",
      "hyp: set , ref: setup\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.7499999953125\n",
      "hyp: set , ref: setup\n",
      "\n",
      "meteor: 0.0\n",
      "symb. rouge-lF: 0.7499999953125\n",
      "hyp: set , ref: setup\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('threshold:', 0.6)\n",
    "print('count:', specific[0].shape[0])\n",
    "print()\n",
    "\n",
    "for s in specific[0]:\n",
    "    print('meteor:', symb_metrics['scores']['meteor'][s])\n",
    "    print('symb. rouge-lF:', symb_metrics['scores']['symb-rouge-lF'][s])\n",
    "    print('hyp:', hyps[s], ', ref:', refs[s])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_methods = [\n",
    "    ('Adam', 'adam_global_predictions.pkl'),\n",
    "#     ('Cyclic SGD', './outputs/global_Cycle_SGD_test_outputs.pkl'),\n",
    "    ('Lamb', 'Lamb_global_predictions.pkl'),\n",
    "    ('LaRAdam', 'Lookahead_Radam_standart_lr/tensor/Lookahead_RAdam_test_outputs.pkl'),\n",
    "#     ('LaAdam', './outputs/global_Lookahead_test_outputs.pkl'),\n",
    "    ('RAdam', 'RAdam_global/tensor/RAdam_test_outputs.pkl'),\n",
    "    ('SGD', './SGD_global/est_outputs.pkl')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('global_methods_report.data'):\n",
    "\n",
    "    with open('global_methods_report.data', 'rb') as fp:\n",
    "        global_methods_report = pickle.load(fp)\n",
    "\n",
    "else:\n",
    "    global_methods_report = {}\n",
    "\n",
    "    for method, path in global_methods:\n",
    "        hyps, refs = get_hyps_refs(predict_file=path, use_first=None)\n",
    "        metrics = Metrics(hyps, refs)\n",
    "        global_methods_report[method] = metrics.get_statistics()\n",
    "        print(method, global_methods_report[method])\n",
    "\n",
    "    with open('global_methods_report.data', 'wb') as fp:\n",
    "        pickle.dump(global_methods_report, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_methods = [\n",
    "    ('A2GradExp', './outputs/local_A2GradExp_test_outputs.pkl'),\n",
    "    ('Adadelta', './outputs/local_Adadelta_test_outputs.pkl'),\n",
    "    ('Barzilai-Borwein', './outputs/local_BB_test_outputs.pkl'),\n",
    "    ('LaAdam', './outputs/local_Lookahead_test_outputs.pkl'),\n",
    "    ('RAdam', './outputs/local_RAdam_test_outputs.pkl'),\n",
    "    ('SVRG', './outputs/local_SVRG_test_outputs.pkl'),\n",
    "    ('SWA', './outputs/local_SWA_test_outputs.pkl'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('local_methods_report.data'):\n",
    "\n",
    "    with open('local_methods_report.data', 'rb') as fp:\n",
    "        local_methods_report = pickle.load(fp)\n",
    "\n",
    "else:\n",
    "    local_methods_report = {}\n",
    "\n",
    "    for method, path in local_methods:\n",
    "        hyps, refs = get_hyps_refs(predict_file=path, use_first=None)\n",
    "        metrics = Metrics(hyps, refs)\n",
    "        local_methods_report[method] = metrics.get_statistics()\n",
    "        print(method, local_methods_report[method])\n",
    "\n",
    "    with open('local_methods_report.data', 'wb') as fp:\n",
    "        pickle.dump(local_methods_report, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in global_methods_report:\n",
    "    print(method, global_methods_report[method]['score'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for method1, method2 in itertools.combinations(global_methods_report, 2):\n",
    "    print(method1, '-', method2)\n",
    "    for score in global_methods_report[method1]['score']:\n",
    "        print(score, end=' ')\n",
    "        h1 = None\n",
    "        if global_methods_report[method1]['score'][score] > global_methods_report[method2]['score'][score]:\n",
    "            pc = round(100 * (global_methods_report[method1]['score'][score] - global_methods_report[method2]['score'][score]) / global_methods_report[method2]['score'][score], 0)\n",
    "            print('>', f'({pc}%)', end=' ')\n",
    "            h1 = 'less'\n",
    "        else:\n",
    "            pc = round(100 * (global_methods_report[method2]['score'][score] - global_methods_report[method1]['score'][score]) / global_methods_report[method2]['score'][score], 0)\n",
    "            print('<', f'({pc}%)', end=' ')\n",
    "            h1 = 'greater'\n",
    "            \n",
    "        print()\n",
    "        w, p = wilcoxon(\n",
    "            global_methods_report[method1]['scores'][score],\n",
    "            global_methods_report[method2]['scores'][score],\n",
    "            alternative=h1\n",
    "        )\n",
    "        print('wilcoxon signed-rank: w =', round(int(w), -4), ', p =', p)\n",
    "        \n",
    "        s, p = mannwhitneyu(\n",
    "            global_methods_report[method1]['scores'][score],\n",
    "            global_methods_report[method2]['scores'][score],\n",
    "            alternative=h1\n",
    "        )\n",
    "        print('mann-whitneyu: s =', round(int(s), -5), ', p =', p)\n",
    "        \n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "met-opt-exps",
   "language": "python",
   "name": "met-opt-exps"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
